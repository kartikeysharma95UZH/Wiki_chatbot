{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import difflib\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "from spellchecker import SpellChecker\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import re\n",
    "from functools import reduce\n",
    "from word2number import w2n\n",
    "import csv\n",
    "import numpy as np\n",
    "import os\n",
    "import rdflib\n",
    "import pandas as pd\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from transformers import pipeline, set_seed\n",
    "\n",
    "\n",
    "movie_info = pd.read_pickle(r'movies_new_9_12.pkl')\n",
    "human_info = pd.read_pickle(r'humans_9_12.pkl')\n",
    "crew_info = pd.read_pickle(r'movie_crew_9_12.pkl')\n",
    "images_info  = pd.read_pickle(r'images_from_json.pkl')\n",
    "movie_names_df = pd.read_pickle(r'list_of_movies_6_12.pkl')\n",
    "human_names_df = pd.read_pickle(r'list_of_humans_6_12.pkl')\n",
    "movie_multimedia = pd.read_pickle(r'movie_multimedia_6_12.pkl')\n",
    "human_multimedia = pd.read_pickle(r'humans_multimedia_6_12.pkl')\n",
    "entity_code_description_df = pd.read_pickle(r'entity_code_description_9_12.pkl')\n",
    "all_property_code_description_df = pd.read_pickle(r'all_properties_mapping_9_12.pkl')\n",
    "all_entities_code_description_df = pd.read_pickle(r'all_entities_mapping_10_12.pkl')\n",
    "crowdsource_df = pd.read_pickle(r'crowdsource_df.pkl')\n",
    "top_250_imdb_df = pd.read_pickle(r'top_250_imdb_df.pkl')\n",
    "plots_df = pd.read_pickle(r'plots_df.pkl')\n",
    "comments_df = pd.read_pickle(r'comments_df.pkl')\n",
    "rating_codes_df = pd.read_pickle(r'rating_codes_df.pkl')\n",
    "entity_id_df = pd.read_pickle(r'entity_ids_9_12.pkl')\n",
    "relation_id_df = pd.read_pickle(r'relation_ids_9_12.pkl')\n",
    "entity_code_description_df = pd.read_pickle(r'entity_code_description_9_12.pkl')\n",
    "\n",
    "movie_names_list = list(set(movie_names_df['movie names'].tolist()))\n",
    "human_names_list = list(set(human_names_df['human names'].tolist()))\n",
    "\n",
    "# load the embeddings\n",
    "entity_emb = np.load('entity_embeds.npy')\n",
    "relation_emb = np.load('relation_embeds.npy')\n",
    "\n",
    "#from transformers import BertTokenizer, BertModel # for tokenizing and sentiment analysis\n",
    "ner_pipeline = pipeline('ner', model='dbmdz/bert-large-cased-finetuned-conll03-english')\n",
    "# from transformers import pipeline\n",
    "zero_shot_classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "# cachedStopWords = nltk.download('stopwords')\n",
    "cachedStopWords = stopwords.words(\"english\")\n",
    "spell = SpellChecker()\n",
    "nlp=spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "data_2={'property':['cast member','fsk film rating','imdb id','director','editor','nominated for',\n",
    "'based on','box office','designer','citizenship', 'country of origin','subject', 'genre', 'screenwriter', \n",
    " 'occupation', 'photographer', 'publication date', 'production company']\n",
    ",'code':['P161', 'P1981', 'P345', 'P57', 'P1040', 'P1411', 'P144', 'P2142', 'P2554', 'P27', 'P495',\n",
    " 'P921', 'P136', 'P58', 'P106', 'P344', 'P577', 'P272']}\n",
    "\n",
    "selective_propert_codes_df = pd.DataFrame(data_2)\n",
    "# selective_propert_codes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper lists for intent/properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_MULTIMEDIA_words = ['pics', 'images', 'image', 'photo',' photos', 'photograph', 'photographs', 'portrait','portraits', 'still', 'stills', 'poster', 'posters','still frame', 'frame', 'frames', 'picture','pictures', 'look', 'looks']\n",
    "list_of_RECOMMENDATION_words = ['recommend', 'similar', 'recommendations', 'recommendation', 'like']\n",
    "\n",
    "list_of_occupation_words = ['occupation', 'for a living']\n",
    " \n",
    "subcategory_multimedia = ['behind_the_scenes', 'still_frame', 'publicity', 'event', 'poster', 'production_art', 'product', 'user_avatar']\n",
    "\n",
    "list_of_crew = ['director', 'screenwriter', 'cast member', 'editor', 'photographer', 'designer', 'production company']\n",
    "\n",
    "list_of_movie_property = ['description','tags', 'publication date', 'genre',\n",
    " 'rating','nominated','fsk rating','production company','based on'\n",
    ",'cnc rating','imdb id','box office', 'country of origin','filmed location' ,'subject']\n",
    "\n",
    "list_of_human_prop = ['description','occupation', 'language spoken', 'place of birth','citizenship','imdb id']\n",
    "\n",
    "mapper_list_CAST_MEMBER = ['hero' ,'protagonist' ,'star' ,'starring' ,'heroine' ,'lead actor' ,'leading character' ,\n",
    "'main character' , 'leading role', 'principal character' ,'Principal role' ,'star',\n",
    "'chief character', 'chief participant' ,'leading participant' ,'main participant' ,'principal participant' ,\n",
    "'central character' ,'key player', 'leading man' ,'leading figure' , 'superhero' ,\n",
    "'leading performer' ,'leading actress' , 'celebrity', 'icon' ,'main figure']\n",
    "\n",
    "greet_and_rem = ['hey', 'hi', 'hello', 'yo', 'yoo', 'film', 'movies', 'films', 'movie']\n",
    "\n",
    "miscell_list = ['narrative', 'country', 'photography', 'mpaa','fsk','bbfc','rars','kijkwijzer','classind','incaa', 'kmrb','fpb','kavi','medierÃ¥det','ifco','nmhh','iroda','eirin','cnc(france)','icaa','cnc(romania)','jmk','rtc','igac','imda','hongkong','mtrcb','bamid'\n",
    "'publication', 'detention' , 'death', 'birth' , 'place' , 'location' , 'burial', 'location' ,  'character', 'sound', 'art', 'executive', 'director'\n",
    "'production', 'costume', 'designer'  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract NER (excluding recommender questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ner(question):\n",
    "    try:\n",
    "        # question = question.title()\n",
    "        ner = ner_pipeline(question, aggregation_strategy=\"simple\")\n",
    "        print(ner)\n",
    "        if len(ner) == 0:\n",
    "            print(\"INSIDE GET NER FUNCTION.... LENGTH IS 0\")\n",
    "            ner_output = ''\n",
    "            \n",
    "        else:\n",
    "            scores = []\n",
    "            for i in range (len(ner)):\n",
    "                score = scores.append(ner[i]['score'])\n",
    "            max_value = max(scores)\n",
    "            index = scores.index(max_value)\n",
    "            print(\"Index taken = \" + str(index))\n",
    "\n",
    "        ner_output = ner[index]\n",
    "    except:\n",
    "        ner_output = ''\n",
    "\n",
    "    return ner_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract entities (Human + Movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_movie_extractor(question):\n",
    "    try:\n",
    "        ner = get_ner(question)\n",
    "        if len(ner) > 0:\n",
    "\n",
    "            # print(\"***** SOMETHING IS DETECTED BY NER *****\")\n",
    "            entity_dict = ner\n",
    "            if entity_dict['entity_group'] == 'MISC':\n",
    "                mov_human_flag = 'movie'\n",
    "                print(\"we perceive that the question related to the movie is asked ....\")\n",
    "                \n",
    "                if entity_dict['word'] not in movie_names_list:\n",
    "                    # print('*****************')\n",
    "                    received_entity = entity_dict['word']\n",
    "                    expected_movie = difflib.get_close_matches(entity_dict['word'], movie_names_list)[0]\n",
    "                    usable_entity = expected_movie\n",
    "                    # print(\"cannot find the movie. Trying with the closest movie that we have\")\n",
    "                    print(\"Closest movie found!! The expected movie is : \" + expected_movie)\n",
    "                    # print(\"usable entity : \"+ usable_entity)\n",
    "                    # print(\"receieved entity : \"+ received_entity)\n",
    "                    if len(expected_movie) == 0:\n",
    "                        print(\"MOVIE NOT FOUND WITH NER\")\n",
    "                        received_entity = ''\n",
    "                        usable_entity = ''\n",
    "\n",
    "                else:\n",
    "                    received_entity = entity_dict['word']\n",
    "                    usable_entity = received_entity\n",
    "                    print(\"BINGO!! EXCAT MOVIE IS GUESSED WITH NER\")\n",
    "\n",
    "            elif entity_dict['entity_group'] == 'PER':\n",
    "                mov_human_flag = 'human'\n",
    "                print(\"Question related to a PERSON is being asked ....\")\n",
    "\n",
    "                if entity_dict['word'] not in human_names_list:\n",
    "                    received_entity = entity_dict['word']\n",
    "                    expected_human = difflib.get_close_matches(entity_dict['word'], human_names_list)[0]\n",
    "                    usable_entity = expected_human\n",
    "                    # print(\"cannot find the person. Trying with the closest name of person that we have\")\n",
    "                    print(\"Closest person found!! The expected name is : \" + expected_human)\n",
    "                    # received_entity = expected_human ## remember to pass the original movie that the user entered to delete it from the question\n",
    "                    if len(expected_human) == 0:\n",
    "                        print(\"HUMAN NOT FOUND WITH NER\")\n",
    "                        received_entity = ''\n",
    "                        usable_entity = ''\n",
    "                else:\n",
    "                    received_entity = entity_dict['word']\n",
    "                    usable_entity = received_entity\n",
    "                    # expected_entity = ''\n",
    "                #print(\"the name of the person is : \" + received_entity)\n",
    "\n",
    "            else: ##GUESSing\n",
    "                print(\"GUESSING SOME MOVIE/HUMAN USING NER\")\n",
    "                received_entity = entity_dict['word']\n",
    "                expected_guess_1 = difflib.get_close_matches(entity_dict['word'], human_names_list)\n",
    "                expected_guess_2 = difflib.get_close_matches(entity_dict['word'], movie_names_list)\n",
    "\n",
    "                best_guess_1_score = 0\n",
    "                best_guess_2_score = 0\n",
    "                movie_found = ''\n",
    "                human_found = ''\n",
    "                \n",
    "                if len(expected_guess_1) > 0:\n",
    "                    best_guess_1 = expected_guess_1[0] \n",
    "                    best_guess_1_score = difflib.SequenceMatcher(None, entity_dict['word'], best_guess_1).ratio()\n",
    "                    if best_guess_1 in human_names_list:\n",
    "                        movie_found = 'yes'\n",
    "\n",
    "                    print(\"score of entity being a human = \" + str(best_guess_1_score))\n",
    "\n",
    "                if len(expected_guess_2) > 0:\n",
    "                    best_guess_2 = expected_guess_2[0] \n",
    "                    best_guess_2_score = difflib.SequenceMatcher(None, entity_dict['word'], best_guess_2).ratio()\n",
    "                    if best_guess_2 in movie_names_list:\n",
    "                        movie_found = 'yes'\n",
    "\n",
    "                    print(\"score of entity being a movie = \" + str(best_guess_2_score))\n",
    "\n",
    "\n",
    "                if len(expected_guess_1) == 0 and len(expected_guess_2) == 0:\n",
    "                    usable_entity = ''\n",
    "                    mov_human_flag = ''\n",
    "                    entity_code = ''\n",
    "                    received_entity = ''\n",
    "\n",
    "                    print(\"COULD NOT GUESS THE MOVIE/HUMAN USING NER *****\")\n",
    "\n",
    "                else :\n",
    "                    if best_guess_1_score > best_guess_2_score and human_found == 'yes':\n",
    "                        print(\"Guessing it to be the human from our list\")\n",
    "                        print(\"matching with : \" + best_guess_1)\n",
    "                        usable_entity = best_guess_1\n",
    "                        mov_human_flag = 'human'\n",
    "\n",
    "                    elif best_guess_1_score <=  best_guess_2_score and movie_found == 'yes':\n",
    "                        print(\"Guessing it to be the movie from our list\")\n",
    "                        print(\"matching with : \" + best_guess_2)\n",
    "                        usable_entity = best_guess_2\n",
    "                        mov_human_flag = 'movie'\n",
    "\n",
    "            if len(entity_code_description_df[entity_code_description_df['description'] == usable_entity.lower()]['code']) > 0:\n",
    "                entity_code = entity_code_description_df[entity_code_description_df['description'] == usable_entity.lower()]['code'].item()\n",
    "            else :\n",
    "                entity_code = ''\n",
    "\n",
    "        if len(ner) == 0 or usable_entity == '' or entity_code == '' :\n",
    "            print(\"ENTITY NOT FOUND USING NER\")\n",
    "            usable_entity, entity_code = fin_entity_matching(question)\n",
    "            received_entity = usable_entity\n",
    "            if len(usable_entity) == 0 :\n",
    "                print(\"ENTITY NOT FOUND USING REGEXXX TOOO\")\n",
    "                usable_entity = '' \n",
    "                entity_code = ''\n",
    "                mov_human_flag = ''\n",
    "                received_entity = ''\n",
    "                return mov_human_flag, received_entity, usable_entity, entity_code\n",
    "            else:\n",
    "                print(\"ENTITY FOUND USING REGEXXXXX \" + str(usable_entity))\n",
    "                if usable_entity in human_names_list:\n",
    "                    mov_human_flag = 'human'\n",
    "                else:\n",
    "                    mov_human_flag = 'movie'\n",
    "                \n",
    "    except:\n",
    "        mov_human_flag = ''\n",
    "        received_entity = ''\n",
    "        usable_entity = ''\n",
    "        entity_code = ''\n",
    "\n",
    "    return mov_human_flag, received_entity, usable_entity, entity_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract n entities for recommender system \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_movie_extractor_recommender(ner):\n",
    "    try:\n",
    "        print(\"***** INSIDE human_movie_extractor *****\")\n",
    "        # entity_dict = ner[0]\n",
    "        entity_dict = ner\n",
    "        if entity_dict['entity_group'] == 'MISC':\n",
    "            mov_human_flag = 'movie'\n",
    "            print(\"WE PERCEIVE THAT IT CAN BE A MOVIE Question ....\")\n",
    "            \n",
    "            if entity_dict['word'] not in movie_names_list:\n",
    "                print('*****************')\n",
    "                received_entity = entity_dict['word']\n",
    "                expected_movie = difflib.get_close_matches(entity_dict['word'], movie_names_list)[0]\n",
    "                usable_entity = expected_movie\n",
    "                print(\"cannot find the movie. Trying with the closest movie that we have\")\n",
    "                print(\"CLOSEST MATCH OF THE MOVIE IS FOUND =  \" + expected_movie)\n",
    "                # print(\"usable entity : \"+ usable_entity)\n",
    "                # print(\"receieved entity : \"+ received_entity)\n",
    "                # received_entity = expected_movie ## remember to pass the original movie that the user entered to delete it from the question\n",
    "                if len(expected_movie) == 0:\n",
    "                    print(\"CANNOT FIND THE MOVIE WITH THE NER\")\n",
    "                    received_entity = ''\n",
    "                    usable_entity = ''\n",
    "                    mov_human_flag = ''\n",
    "            else:\n",
    "                received_entity = entity_dict['word']\n",
    "                usable_entity = received_entity\n",
    "                print(\"WE HAVE RECEIVED THE EXACT MOVIE FROM NER = \" + str(usable_entity))\n",
    "                print(\"WILL EXTRACT THE CODE OF THE MOVIE NOW\")\n",
    "                # expected_entity = ''\n",
    "            # print(\"Working on the movie : \" + received_entity)\n",
    "\n",
    "        elif entity_dict['entity_group'] == 'PER':\n",
    "            mov_human_flag = 'human'\n",
    "            print(\"Question related to a PERSON is being asked ....\")\n",
    "\n",
    "            if entity_dict['word'] not in human_names_list:\n",
    "                received_entity = entity_dict['word']\n",
    "                expected_human = difflib.get_close_matches(entity_dict['word'], human_names_list)[0]\n",
    "                usable_entity = expected_human\n",
    "                print(\"cannot find the person. Trying with the closest name of person that we have\")\n",
    "                print(\"Closest person found!! The expected name is : \" + expected_human)\n",
    "                # received_entity = expected_human ## remember to pass the original movie that the user entered to delete it from the question\n",
    "                if len(expected_human) == 0:\n",
    "                    print(\"CANNOT FIND THE HUMAN WITH THE NER\")\n",
    "                    received_entity = ''\n",
    "                    usable_entity = ''\n",
    "                    mov_human_flag = ''\n",
    "            else:\n",
    "                received_entity = entity_dict['word']\n",
    "                usable_entity = received_entity\n",
    "                print(\"WE HAVE RECEIVED THE EXACT HUMAN NAME FROM NER\")\n",
    "                # expected_entity = ''\n",
    "            #print(\"the name of the person is : \" + received_entity)\n",
    "\n",
    "        else: ##GUESSing\n",
    "            print(\"GUESSSING THE NAME OF THE MOVIE OR THE HUMAN FROM NER\")\n",
    "            received_entity = entity_dict['word']\n",
    "            expected_guess_1 = difflib.get_close_matches(entity_dict['word'], human_names_list)\n",
    "            expected_guess_2 = difflib.get_close_matches(entity_dict['word'], movie_names_list)\n",
    "\n",
    "            best_guess_1_score = 0\n",
    "            best_guess_2_score = 0\n",
    "            movie_found = ''\n",
    "            human_found = ''\n",
    "            \n",
    "            if len(expected_guess_1) > 0:\n",
    "                best_guess_1 = expected_guess_1[0] \n",
    "                best_guess_1_score = difflib.SequenceMatcher(None, entity_dict['word'], best_guess_1).ratio()\n",
    "                if best_guess_1 in human_names_list:\n",
    "                    movie_found = 'yes'\n",
    "\n",
    "                print(\"score of entity being a human = \" + str(best_guess_1_score))\n",
    "\n",
    "            if len(expected_guess_2) > 0:\n",
    "                best_guess_2 = expected_guess_2[0] \n",
    "                best_guess_2_score = difflib.SequenceMatcher(None, entity_dict['word'], best_guess_2).ratio()\n",
    "                if best_guess_2 in movie_names_list:\n",
    "                    movie_found = 'yes'\n",
    "\n",
    "                print(\"score of entity being a movie = \" + str(best_guess_2_score))\n",
    "\n",
    "\n",
    "            if len(expected_guess_1) == 0 and len(expected_guess_2) == 0:\n",
    "                print(\"COULD NOT DECIDE IF THE ENTITY IS MOVIE OR HUMAN..... ---> GOING TO THE REGEXXXX\")\n",
    "                usable_entity = ''\n",
    "                mov_human_flag = ''\n",
    "                entity_code = ''\n",
    "                received_entity = ''\n",
    "                \n",
    "\n",
    "            else :\n",
    "                if best_guess_1_score > best_guess_2_score and human_found == 'yes':\n",
    "                    print(\"Guessing it to be the human from our list\")\n",
    "                    print(\"matching with : \" + best_guess_1)\n",
    "                    usable_entity = best_guess_1\n",
    "                    mov_human_flag = 'human'\n",
    "\n",
    "                elif best_guess_1_score <=  best_guess_2_score and movie_found == 'yes':\n",
    "                    print(\"Guessing it to be the movie from our list\")\n",
    "                    print(\"matching with : \" + best_guess_2)\n",
    "                    usable_entity = best_guess_2\n",
    "                    mov_human_flag = 'movie'\n",
    "\n",
    "        if len(entity_code_description_df[entity_code_description_df['description'] == usable_entity.lower()]['code']) > 0:\n",
    "            entity_code = entity_code_description_df[entity_code_description_df['description'] == usable_entity.lower()]['code'][:1].item()\n",
    "            print(\"YAYYY!! WE ALSO GOT THE CODE FOR THE ENTITY = \" + str(usable_entity) + \" The code  = \" + str(entity_code))\n",
    "            # print(\"ENTTY CODE FOR THE MOVIE \" + usable_entity + \" IS = \" + str(entity_code))\n",
    "            return mov_human_flag, received_entity, usable_entity, entity_code\n",
    "        else :\n",
    "            entity_code = ''\n",
    "            print(\"DID NOT RECEIVE THE ENTITY CODE FROM THE NER. WILL LOOK FOR THE NEW ENTITY NAME USIGN REGEXXXX\")\n",
    "\n",
    "        if usable_entity == '' or entity_code == '' :\n",
    "            print(\"ENTITY NOT FOUND USING NER.... TRYING WIHT REGEXXX NOW\")\n",
    "            usable_entity, entity_code = fin_entity_matching(question)\n",
    "            received_entity = usable_entity\n",
    "            if len(usable_entity) == 0 :\n",
    "                print(\"ENTITY NOT FOUND USING REGEXXX TOOO\")\n",
    "                usable_entity = '' \n",
    "                entity_code = ''\n",
    "                mov_human_flag = ''\n",
    "                received_entity = ''\n",
    "                return mov_human_flag, received_entity, usable_entity, entity_code\n",
    "            else:\n",
    "                print(\"ENTITY FOUND USING REGEXXXXX\" + str(usable_entity))\n",
    "                if usable_entity in human_names_list:\n",
    "                    mov_human_flag = 'human'\n",
    "                else:\n",
    "                    mov_human_flag = 'movie'\n",
    "\n",
    "    except:\n",
    "        mov_human_flag = ''\n",
    "        received_entity = ''\n",
    "        usable_entity = ''\n",
    "        entity_code = ''\n",
    "\n",
    "    return mov_human_flag, received_entity, usable_entity, entity_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing the entity name from the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entity_remove_from_question(ques, received_entity):\n",
    "    ques = ques.title()\n",
    "    # print(\"***** INSIDE entity_remove_from_question *****\")\n",
    "    rem_ques = ques.replace(received_entity, '')\n",
    "    print('Remaining question after removing the movie name : ' + rem_ques)\n",
    "    \n",
    "    return rem_ques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing stop words from the remaining question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_word_removal(ques, cachedStopWords):\n",
    "    ques = ques.lower()\n",
    "    rem_ques = ' '.join([word for word in ques.split() if word not in cachedStopWords])\n",
    "    print('Remaining question after removing the stop words : ' + rem_ques)\n",
    "    return rem_ques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Property extractor --> 'movie'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def property_extractor_movie(ques):\n",
    "    print(\"***** INSIDE property_extractor_movie *****\")\n",
    "    for word in ques.split():\n",
    "\n",
    "        # words.append(word)\n",
    "        expected_actor = difflib.get_close_matches(word.lower(), mapper_list_CAST_MEMBER)\n",
    "        # expected_actor_score = difflib.SequenceMatcher(None, word.lower(), expected_actor[0]).ratio()\n",
    "        # print(\"nearest actor_entity : \" + str(expected_actor))\n",
    "        expected_prop_movie = difflib.get_close_matches(word.lower(), list_of_movie_property)\n",
    "        # expected_prop_movie_score = difflib.SequenceMatcher(None, word.lower(), expected_prop_movie[0]).ratio()\n",
    "        # print(\"nearest expected_prop_movie : \" + str(expected_prop_movie))\n",
    "        expected_crew_member = difflib.get_close_matches(word.lower(), list_of_crew)  \n",
    "        # expected_crew_member_score = difflib.SequenceMatcher(None, word.lower(), expected_crew_member[0]).ratio()\n",
    "        # print(\"nearest expected_crew_member : \" + str(expected_crew_member))\n",
    "\n",
    "        if len(expected_crew_member) > 0 :\n",
    "            # expected_crew_member_score = difflib.SequenceMatcher(None, word.lower(), expected_crew_member[0]).ratio()\n",
    "            print(\"For Movie, expected crew member is :\" + expected_crew_member[0])\n",
    "            print(\"original word is : \" + word.lower())\n",
    "            target_property = expected_crew_member[0]\n",
    "            table_to_query = crew_info\n",
    "            break\n",
    "\n",
    "        if len(expected_actor) > 0 :#and expected_actor_score > expected_prop_movie_score:\n",
    "            # expected_actor_score = difflib.SequenceMatcher(None, word.lower(), expected_actor[0]).ratio()\n",
    "            print(\"For Movie, expected subset of cast member is :\" + expected_actor[0])\n",
    "            print(\"original word is : \" + word.lower())\n",
    "            target_property = 'cast member'\n",
    "            table_to_query = crew_info\n",
    "            break\n",
    "        \n",
    "        if len(expected_prop_movie) > 0 :\n",
    "            # expected_prop_movie_score = difflib.SequenceMatcher(None, word.lower(), expected_prop_movie[0]).ratio()\n",
    "            print(\"For Movie, No crew member property is asked\")\n",
    "            print(\"expected property is : \" + expected_prop_movie[0])\n",
    "            print(\"original word is : \" + word.lower())\n",
    "            target_property = expected_prop_movie[0]\n",
    "            table_to_query = movie_info\n",
    "            break\n",
    "\n",
    "    try: target_property\n",
    "    except NameError: target_property = None\n",
    "\n",
    "    if target_property is None:\n",
    "        target_property = ''\n",
    "        table_to_query = ''\n",
    "        property_code = ''\n",
    "        return target_property, table_to_query, property_code\n",
    "\n",
    "    elif len(selective_propert_codes_df[selective_propert_codes_df['property'] == target_property]['code']) > 0:\n",
    "        property_code  = selective_propert_codes_df[selective_propert_codes_df['property'] == target_property]['code'].item()\n",
    "    else :\n",
    "        property_code = ''\n",
    "        print(\"Property Code received is\" + str(property_code))\n",
    "\n",
    "    print('target property sent by property extractor = ' + target_property)\n",
    "    return target_property, table_to_query, property_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Property extractor --> 'Human'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def property_extractor_human(ques):\n",
    "    print(\"***** INSIDE property_extractor_movie *****\")\n",
    "    for word in ques.split():\n",
    "        expected_prop_human = difflib.get_close_matches(word.lower(), list_of_human_prop)\n",
    "        print(\"nearest expected_prop_human : \" + str(expected_prop_human))\n",
    "\n",
    "        if word.lower() == 'who':\n",
    "            print(\"Description of human\")\n",
    "            target_property = 'description'\n",
    "            table_to_query = human_info\n",
    "            break\n",
    "\n",
    "        if len(expected_prop_human) > 0:\n",
    "            print(\"expected property is : \" + expected_prop_human[0])\n",
    "            print(\"original word is : \" + word.lower())\n",
    "            target_property = expected_prop_human[0]\n",
    "            table_to_query = human_info\n",
    "            break\n",
    "\n",
    "    try: target_property\n",
    "    except NameError: target_property = None\n",
    "\n",
    "    if target_property is None:\n",
    "        target_property = ''\n",
    "        table_to_query = ''\n",
    "        property_code = ''\n",
    "        return target_property, table_to_query, property_code\n",
    "\n",
    "    elif len(selective_propert_codes_df[selective_propert_codes_df['property'] == target_property]['code']) > 0:\n",
    "        property_code  = selective_propert_codes_df[selective_propert_codes_df['property'] == target_property]['code'].item()\n",
    "    else :\n",
    "        property_code = ''\n",
    "        print(\"Property Code received is\" + str(property_code))\n",
    "    print('target property sent by human property extractor = ' + target_property)\n",
    "    return target_property, table_to_query, property_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factual Result generator --> 'Movie'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_generator_movie(target_property, table_to_query, movie_name):\n",
    "\n",
    "    print(\"***** INSIDE result_generator_movie *****\")\n",
    "    print(\"target property received by result generator is : \" +target_property)\n",
    "    print(\"movie name is : \" + movie_name)\n",
    "\n",
    "    if len(table_to_query[table_to_query['movie label'] == movie_name]) > 0:\n",
    "        value_rows = table_to_query[table_to_query['movie label'] == movie_name]\n",
    "        target_movie_info = list(set(value_rows[target_property].iloc[:1].item()))[0]\n",
    "    else:\n",
    "        target_movie_info = ''\n",
    "        result_code = ''\n",
    "\n",
    "    if len(entity_code_description_df[entity_code_description_df['description'] == target_movie_info.lower()]['code']) > 0 :\n",
    "        result_code = entity_code_description_df[entity_code_description_df['description'] == target_movie_info.lower()]['code'].iloc[:1].item()\n",
    "    else :\n",
    "        result_code = ''\n",
    "\n",
    "    if target_movie_info == 'None':\n",
    "        target_movie_info = ''\n",
    "        result_code = ''\n",
    "\n",
    "    return target_movie_info, result_code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factual Result generator --> 'Human'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_generator_human(target_property, table_to_query, human_name):\n",
    "    print(\"target property received by result generatoris : \" +target_property) \n",
    "    print(\"human name is : \" + human_name)\n",
    "\n",
    "    if len(table_to_query[table_to_query['human name'] == human_name]) > 0:\n",
    "        value_rows = table_to_query[table_to_query['human name'] == human_name]\n",
    "        target_human_info = list(set(value_rows[target_property].iloc[:1].item()))[0]\n",
    "\n",
    "    else:\n",
    "        target_human_info = ''\n",
    "        result_code = ''\n",
    "\n",
    "    if len(entity_code_description_df[entity_code_description_df['description'] == target_human_info.lower()]['code']) > 0 :\n",
    "        result_code = entity_code_description_df[entity_code_description_df['description'] == target_human_info.lower()]['code'].iloc[:1].item()\n",
    "    else :\n",
    "        result_code = ''\n",
    "    \n",
    "    if target_human_info == 'None':\n",
    "        target_human_info = ''\n",
    "        result_code = ''\n",
    "\n",
    "    return target_human_info  , result_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Universal property extractor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def universal_property_extractor(rem_question):\n",
    "    try:\n",
    "        target_property= ''\n",
    "        target_property_code = ''\n",
    "        for word in rem_question.split():\n",
    "            expected_property = difflib.get_close_matches(word.lower(), all_property_code_description_df.description.values.tolist())\n",
    "            print(\"nearest UNIVERSAL PRPERTY expected property : \" + str(expected_property))\n",
    "            if len(expected_property) > 0:\n",
    "                print(\"expected UNIVERSAL PRPERTY property is : \" + expected_property[0])\n",
    "                print(\"original UNIVERSAL PRPERTY word is : \" + word.lower())\n",
    "                target_property = expected_property[0]\n",
    "                target_property_code = all_property_code_description_df[all_property_code_description_df['description'] == target_property]['code'].item()\n",
    "                break\n",
    "    except:\n",
    "        target_property= ''\n",
    "        target_property_code = ''\n",
    "    return target_property, target_property_code\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get Factual Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_factual_answers(question):\n",
    "    usable_entity = '' \n",
    "    entity_code = ''\n",
    "    target_property = ''\n",
    "    prop_code = ''\n",
    "    result_label = ''\n",
    "    result_code = ''\n",
    "    mov_human_flag = ''\n",
    "    \n",
    "    mov_human_flag,received_entity,usable_entity, entity_code = human_movie_extractor(question)\n",
    "\n",
    "    if len(usable_entity) == 0 :\n",
    "        print(\"ENTITY NOT FOUND  NEITHER WITH REGEXXX NOR WITH NER\")\n",
    "        usable_entity = '' \n",
    "        entity_code = ''\n",
    "        target_property = ''\n",
    "        prop_code = ''\n",
    "        result_label = ''\n",
    "        result_code = ''\n",
    "        mov_human_flag = ''\n",
    "        return usable_entity, entity_code, target_property, prop_code, result_label, result_code, mov_human_flag\n",
    "    else:\n",
    "        rem_ques = entity_remove_from_question(question, received_entity)\n",
    "        miscell_flag = check_miscel_intents(question)\n",
    "        if mov_human_flag == 'movie': # ONLY FOR FACTUAL\n",
    "            \n",
    "            if miscell_flag == 'comment':\n",
    "                print('providing comments from movie answers')\n",
    "                result_label = ''\n",
    "                target_property = 'comment'\n",
    "                result_code = ''\n",
    "                prop_code = ''\n",
    "                return usable_entity, entity_code, target_property, prop_code, result_label, result_code, mov_human_flag\n",
    "\n",
    "            elif miscell_flag == 'plot':\n",
    "                print('providing plot of movie answers')\n",
    "                result_label = ''\n",
    "                target_property = 'plot'\n",
    "                result_code = ''\n",
    "                prop_code = ''\n",
    "                return usable_entity, entity_code, target_property, prop_code, result_label, result_code, mov_human_flag\n",
    "  \n",
    "            else:\n",
    "                target_property, table_to_query_movie, prop_code = property_extractor_movie(rem_ques)\n",
    "                if len(target_property) > 0:\n",
    "                    result_label, result_code = result_generator_movie(target_property, table_to_query_movie, usable_entity)\n",
    "                    print(result_label, result_code)\n",
    "                    print('Entity Code of movie= ' + entity_code + \" &&& Entity Name  of movie= \" + usable_entity)\n",
    "                    print('Property Code of movie = ' + prop_code + \" &&& Property Name of Movie = \" + target_property)\n",
    "                    print('Result Code of movie = ' + result_code + \" &&& Result Label of movie = \" + result_label)\n",
    "                else :\n",
    "                    result_label = ''\n",
    "                    result_code = ''\n",
    "\n",
    "        elif mov_human_flag == 'human':\n",
    "            target_property, table_to_query_human, prop_code = property_extractor_human(rem_ques)\n",
    "            if len(target_property) > 0:\n",
    "                result_label, result_code = result_generator_human(target_property, table_to_query_human, usable_entity)\n",
    "                print(result_label, result_code)\n",
    "                print('Entity Code  of human= ' + entity_code + \" &&& Entity Name  of human = \" + usable_entity)\n",
    "                print('Property Code  of human= ' + prop_code + \" &&& Property Name  of human = \" + target_property)\n",
    "                print('Result Code  of human= ' + result_code + \" &&& Result Label  of human = \" + result_label)\n",
    "            else :\n",
    "                result_label = ''\n",
    "                result_code = ''\n",
    "    \n",
    "    return usable_entity, entity_code, target_property, prop_code, result_label, result_code, mov_human_flag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check factual answers with embedding answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# property_code = 'P1431'\n",
    "# entity_code = 'Q223596'\n",
    "# result_code = 'Q329737'\n",
    "# result_label = 'butcher'\n",
    "def get_factual_embedding_rank(property_code, entity_code, result_code, result_label):\n",
    "    head = entity_emb[int(entity_id_df[entity_id_df['entity_id names'] == entity_code]['index'])]\n",
    "    pred = relation_emb[int(relation_id_df[relation_id_df['relation_id names'] == property_code]['index'])]\n",
    "    lhs = head + pred\n",
    "    dist = pairwise_distances(lhs.reshape(1, -1), entity_emb).reshape(-1)\n",
    "    most_likely = dist.argsort()\n",
    "    ranks = dist.argsort().argsort()\n",
    "\n",
    "    factual_rank = ranks[int(entity_id_df[entity_id_df['entity_id names'] == result_code]['index'])]\n",
    "\n",
    "    for rank, idx in enumerate(most_likely[:1]):\n",
    "        embedding_result_label = entity_code_description_df[entity_code_description_df['code'] == entity_id_df[entity_id_df['index'] == str(idx)]['entity_id names'].item()]['description'].item()\n",
    "        embedding_rank = rank+1\n",
    "\n",
    "    return factual_rank, embedding_rank, embedding_result_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. EMBEDDING ANSWERS :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_result(property_code, entity_code):\n",
    "    try:\n",
    "        head = entity_emb[int(entity_id_df[entity_id_df['entity_id names'] == entity_code]['index'])]\n",
    "        pred = relation_emb[int(relation_id_df[relation_id_df['relation_id names'] == property_code]['index'])]\n",
    "        lhs = head + pred\n",
    "        dist = pairwise_distances(lhs.reshape(1, -1), entity_emb).reshape(-1)\n",
    "        most_likely = dist.argsort()\n",
    "        ranks = dist.argsort().argsort()\n",
    "\n",
    "        for rank, idx in enumerate(most_likely[:1]):\n",
    "            embedding_result_label = entity_code_description_df[entity_code_description_df['code'] == entity_id_df[entity_id_df['index'] == str(idx)]['entity_id names'].item()]['description'].item()\n",
    "            embedding_rank = rank+1\n",
    "    except:\n",
    "        embedding_result_label = ''\n",
    "    return embedding_result_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. MULTIMEDIA ANSWERS :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(ques):\n",
    "\n",
    "    mov_human_flag, _, entity_name, _ = human_movie_extractor(ques)\n",
    "\n",
    "    image_type = 'still_frame'\n",
    "    target_property = 'imdb id'\n",
    "\n",
    "    if mov_human_flag == 'human':\n",
    "\n",
    "        table_to_query = human_info\n",
    "        human_name = entity_name\n",
    "        imdb_code = result_generator_human(target_property, table_to_query, human_name)\n",
    "        imdb_code = list(imdb_code)\n",
    "        mask = images_info.cast.apply(lambda x: any(item for item in imdb_code if item in x))\n",
    "        possible_options = images_info[mask]\n",
    "        # print(possible_options)\n",
    "        # sel_option = possible_options[possible_options['type'] == image_type].iloc[0]  'Here is the image image:3543/rm1853225728'\n",
    "        if len(possible_options[possible_options['type'] == image_type]) > 0:\n",
    "            sel_option = possible_options[possible_options['type'] == image_type].iloc[0]\n",
    "            image = sel_option['img'][:-4]\n",
    "            render_image = \"Here is the image of \" + human_name +  \" image:\" + str(image)\n",
    "            print(\"Image URL is : \" + render_image)\n",
    "        elif len(possible_options) > 0:\n",
    "            sel_option = possible_options.iloc[0]\n",
    "            image = sel_option['img'][:-4]\n",
    "            render_image = \"Here is the image of \" + human_name +  \" image:\" + str(image)\n",
    "            print(\"Image URL is : \" + render_image)\n",
    "        else :\n",
    "            render_image = 'Dear human, I was unable to find the required image of ' + entity_name\n",
    "\n",
    "    elif mov_human_flag == 'movie':\n",
    "\n",
    "        # print('$$$$$$$$$$$$$$$$$$$$$')\n",
    "        table_to_query = movie_info\n",
    "        movie_name = entity_name\n",
    "        imdb_code = result_generator_movie(target_property, table_to_query, movie_name)\n",
    "        imdb_code = list(imdb_code)\n",
    "        # print(str(imdb_code) + 'sdfsdfsdgsdgsdgsdgsdg')\n",
    "        mask = images_info.movie.apply(lambda x: any(item for item in imdb_code if item in x))\n",
    "        possible_options = images_info[mask]\n",
    "        # print(possible_options)\n",
    "        # sel_option = possible_options[possible_options['type'] == image_type].iloc[0]\n",
    "        if len(possible_options[possible_options['type'] == image_type]) > 0:\n",
    "            sel_option = possible_options[possible_options['type'] == image_type].iloc[0]\n",
    "            image = sel_option['img'][:-4]\n",
    "            render_image = \"Here is the image from \" + movie_name +  \" image:\" + str(image)\n",
    "            print(\"Image URL is : \" + render_image)\n",
    "        elif len(possible_options) > 0:\n",
    "            sel_option = possible_options.iloc[0]\n",
    "            image = sel_option['img'][:-4]\n",
    "            render_image = \"Here is the image from \" + movie_name +  \" image:\" + str(image)\n",
    "            print(\"Image URL is : \" + render_image)\n",
    "        else :\n",
    "            render_image = 'Dear human, I was unable to find the desired image from the movie : ' + entity_name\n",
    "    \n",
    "    else :\n",
    "        render_image = 'Dear human, I was unable to find the desired image. Please give me another chance with a different entity'\n",
    "    \n",
    "    return render_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. RECOMMENDATION :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_entites_recommender(question):\n",
    "    # question = question.title()\n",
    "    try:\n",
    "        ner = ner_pipeline(question, aggregation_strategy=\"simple\")\n",
    "        print(ner)\n",
    "        if len(ner) == 0:\n",
    "            # print(\"Sorry, I did not understand the question\")\n",
    "            entity_name_list = []\n",
    "            entity_code_list = []\n",
    "        else:\n",
    "            entity_name_list = []\n",
    "            entity_code_list = []\n",
    "            for i in range (len(ner)):\n",
    "                _, _, usable_entity, entity_code = human_movie_extractor_recommender(ner[i]) \n",
    "                print(\"entity name = \" + usable_entity + \"entity code = \" + entity_code)\n",
    "                if len(entity_code) > 0 :\n",
    "                    entity_name_list.append(usable_entity)\n",
    "                    entity_code_list.append(entity_code)\n",
    "        print(\"SENDING THE ENTITY LIST AND LABELS\")\n",
    "        print(\"ENTIT LABELS SENT TO RECOMMENDER SYSTEM  = \" + str(entity_name_list))\n",
    "        print(\"ENTIT CODE  SENT TO RECOMMENDER SYSTEM  = \" + str(entity_code_list))\n",
    "    except:\n",
    "        print(\"COULD NOT IDENTIFY ANY ENTITIES SO THE RESULT WOULD BE AN EMPTY LIST\")\n",
    "        entity_name_list = []\n",
    "        entity_code_list = []\n",
    "    return entity_name_list, entity_code_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations_n_entity(question):\n",
    "    try:\n",
    "        list_entity_labels, list_entity_codes = get_n_entites_recommender(question)\n",
    "        print(\"GOT THE ENTITY LISTS AND LABELS FOR THE RECOMMENDATIONS\")\n",
    "        list_entity_labels = list(map(str.lower,list_entity_labels))\n",
    "        num_of_recommendations = len(list_entity_codes) + 5\n",
    "        s_entity_emb = np.zeros(shape = (256,))\n",
    "        for entity_code in list_entity_codes:\n",
    "            # print(entity_code)\n",
    "            s_entity_emb = s_entity_emb + entity_emb[int(entity_id_df[entity_id_df['entity_id names'] == entity_code]['index'])]\n",
    "\n",
    "        # avg_entity_emb = s_entity_emb/len(list_entity_codes)\n",
    "\n",
    "        dist = pairwise_distances(s_entity_emb.reshape(1, -1) , entity_emb).reshape(-1)\n",
    "        most_likely = dist.argsort()\n",
    "\n",
    "        embedding_result_label = []\n",
    "        for rank, idx in enumerate(most_likely[:num_of_recommendations]):\n",
    "            entity_codes_embed = entity_id_df[entity_id_df['index'] == str(idx)]['entity_id names'].item()\n",
    "            # print(entity_codes_embed)\n",
    "            if len(entity_code_description_df[entity_code_description_df['code'] == entity_codes_embed]['description']) == 0:\n",
    "                continue\n",
    "            else :\n",
    "                entity_labels_embed = entity_code_description_df[entity_code_description_df['code'] == entity_codes_embed]['description']\n",
    "                # print(entity_labels_embed)\n",
    "                embedding_result_label.append(entity_labels_embed.item())\n",
    "            # embedding_result_label.append(entity_code_description_df[entity_code_description_df['code'] == entity_id_df[entity_id_df['index'] == str(idx)]['entity_id names'].item()]['description'].item())\n",
    "            # embedding_rank = rank+1\n",
    "        result = [x for x in embedding_result_label if x not in list_entity_labels]\n",
    "        if len(result) > 0:\n",
    "            result_text = ', '.join([str(x).title() for x in result])\n",
    "            result = \"Based on your interests I can recommend you : \" +  result_text\n",
    "        else :\n",
    "            result_text = ', '.join([str(x).title() for x in list_entity_labels])\n",
    "            result = \"Based on your interests I can recommend you : \" +  result_text\n",
    "\n",
    "    except:\n",
    "        result_text = ', '.join([str(x).title() for x in list_entity_labels])\n",
    "        result = \"Based on your interests I can recommend you : \" +  result_text\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. CROWDSOURCING :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crowd_source_data(entity_code, property_code):\n",
    "    # if len(crowdsource_df[crowdsource_df['Input1ID'] == entity_code]) > 0 and len(crowdsource_df[crowdsource_df['Input2ID'] == property_code]) > 0:\n",
    "    if len(crowdsource_df[(crowdsource_df['Input2ID'] == property_code) & (crowdsource_df['Input1ID'] == entity_code)]) == 1 : \n",
    "        # print('#####')\n",
    "        correct_labeled = crowdsource_df[(crowdsource_df['Input2ID'] == property_code) & (crowdsource_df['Input1ID'] == entity_code)]['CORRECT'].item()\n",
    "        incorrect_labeled =  crowdsource_df[(crowdsource_df['Input2ID'] == property_code) & (crowdsource_df['Input1ID'] == entity_code)]['INCORRECT'].item()\n",
    "        result = crowdsource_df[(crowdsource_df['Input2ID'] == property_code) & (crowdsource_df['Input1ID'] == entity_code)]['Input3ID'].item()\n",
    "        print(result)\n",
    "\n",
    "        if result.startswith('P'):\n",
    "            if len(all_property_code_description_df[all_property_code_description_df['code'] == result]['description']) > 0:\n",
    "                result_label  = all_property_code_description_df[all_property_code_description_df['code'] == result]['description'].item()\n",
    "            else:\n",
    "                result_label = '' \n",
    "        elif result.startswith('Q'):\n",
    "            if len(all_entities_code_description_df[all_entities_code_description_df['code'] == result]['description']) > 0:\n",
    "                result_label  = all_entities_code_description_df[all_entities_code_description_df['code'] == result]['description'].item()\n",
    "            else:\n",
    "                result_label = '' \n",
    "        else :\n",
    "            result_label = result\n",
    "\n",
    "    else:\n",
    "        result_label= ''\n",
    "        correct_labeled = ''\n",
    "        incorrect_labeled = ''\n",
    "\n",
    "    return result_label, correct_labeled, incorrect_labeled\n",
    "\n",
    "\n",
    "# get_crowd_source_data('Q1032889', 'P58')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intent Identification : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating_intent_get_property(ques):\n",
    "    ques = ques.lower()\n",
    "    property_label = ''\n",
    "    property_code = ''\n",
    "    for word in ques.split():\n",
    "        # print(word)\n",
    "        if word in rating_codes_df['description'].values.tolist():\n",
    "            property_label = word\n",
    "            property_code = rating_codes_df[rating_codes_df['description'] == word]['code'].item()\n",
    "            return property_label, property_code\n",
    "    if len(property_code) == 0:\n",
    "        property_label = 'FSK film rating'\n",
    "        property_code = 'P1981'\n",
    "        return property_label, property_code\n",
    "\n",
    "    return property_label, property_code\n",
    "\n",
    "def location_intent_get_property(ques):\n",
    "    ques = ques.lower()\n",
    "    rem_stop_ques = stop_word_removal(ques, cachedStopWords)\n",
    "    property_label = ''\n",
    "    property_code = ''\n",
    "    for word in rem_stop_ques.split():\n",
    "        word = spell.correction(word)\n",
    "        if word in ['work', 'working', 'works', 'worked']:\n",
    "            property_label = 'work location'\n",
    "            property_code = 'P937'\n",
    "            break\n",
    "        elif word in ['narrative', 'narative', 'narration', 'narrated', 'narated', 'narrating', 'narating', 'narrates', 'narates', 'narrate', 'narate']:\n",
    "            property_label = 'narrative location'\n",
    "            property_code = 'P840'\n",
    "            break\n",
    "        elif word in ['origin']:\n",
    "            property_label = 'country of origin'\n",
    "            property_code = 'P495'\n",
    "            break\n",
    "        elif word in ['citizen', 'citizenship', 'passport', 'nationality']:\n",
    "            property_label = 'country of citizenship'\n",
    "            property_code = 'P27'\n",
    "            break\n",
    "        elif word in ['publication', 'published']:\n",
    "            property_label = 'place of publication'\n",
    "            property_code = 'P291'\n",
    "            break\n",
    "        elif word in ['detention', 'detained']:\n",
    "            property_label = 'place of detention'\n",
    "            property_code = 'P2632'\n",
    "            break\n",
    "        elif word in ['death']:\n",
    "            property_label = 'place of death'\n",
    "            property_code = 'P20'\n",
    "            break\n",
    "        elif word in ['birth', 'born', 'birthplace']:\n",
    "            property_label = 'place of birth'\n",
    "            property_code = 'P19'\n",
    "            break\n",
    "        elif word in ['burial', 'buried', 'burried']:\n",
    "            property_label = 'place of burial'\n",
    "            property_code = 'P119'\n",
    "            break\n",
    "            \n",
    "    return property_label, property_code\n",
    "\n",
    "def designer_intent_get_property(ques):\n",
    "    ques = ques.lower()\n",
    "    rem_stop_ques = stop_word_removal(ques, cachedStopWords)\n",
    "    property_label = ''\n",
    "    property_code = ''\n",
    "    for word in rem_stop_ques.split():\n",
    "        word = spell.correction(word)\n",
    "        if word in ['character', 'characters']:\n",
    "            property_label = 'character designer'\n",
    "            property_code = 'P8670'\n",
    "            break\n",
    "        elif word in ['sound', 'sounds']:\n",
    "            property_label = 'sound designer'\n",
    "            property_code = 'P5028'\n",
    "            break\n",
    "        elif word in ['production', 'productions']:\n",
    "            property_label = 'production designer'\n",
    "            property_code = 'P2554'\n",
    "            break\n",
    "        elif word in ['costumes', 'costume']:\n",
    "            property_label = 'costume designer'\n",
    "            property_code = 'P2515'\n",
    "            break\n",
    "    return property_label, property_code\n",
    "\n",
    "def director_intent_get_property(ques):\n",
    "    ques = ques.lower()\n",
    "    rem_stop_ques = stop_word_removal(ques, cachedStopWords)\n",
    "    property_label = ''\n",
    "    property_code = ''\n",
    "    for word in rem_stop_ques.split():\n",
    "        word = spell.correction(word)\n",
    "        print(word)\n",
    "        if word in ['art', 'arts']:\n",
    "            property_label = 'art director'\n",
    "            property_code = 'P3174'\n",
    "            break\n",
    "        elif word in ['photography', 'sounds']:\n",
    "            property_label = 'director of photography'\n",
    "            property_code = 'P344'\n",
    "            break\n",
    "    if len(property_code) == 0:     \n",
    "        property_label = 'director'\n",
    "        property_code = 'P57'\n",
    "    return property_label, property_code\n",
    "\n",
    "def check_image_recommendation(ques):\n",
    "    rem_stop_ques = stop_word_removal(ques, cachedStopWords)\n",
    "    intent_word_image = ''\n",
    "    intent = ''\n",
    "    for word in rem_stop_ques.split():\n",
    "        word = spell.correction(word)\n",
    "        if word in list_of_MULTIMEDIA_words:\n",
    "            print(\"Image question is asked\")\n",
    "            intent = 'image'\n",
    "            intent_word_image = word\n",
    "            break\n",
    "        elif word in list_of_RECOMMENDATION_words:\n",
    "            print(\"Recommendation question asked\")\n",
    "            intent = 'recommendation'\n",
    "            break\n",
    "    return intent, intent_word_image\n",
    "\n",
    "def get_property_from_intents(ques):\n",
    "    # rem_stop_ques = stop_word_removal(ques, cachedStopWords)\n",
    "    ques = ques.lower()\n",
    "    property_label = ''\n",
    "    property_code = ''\n",
    "    for word in ques.split():\n",
    "        word = spell.correction(word)\n",
    "        # print(word)\n",
    "        if word in ['designer', 'designed', 'designing']:    \n",
    "            print('designer_intent_get_property')    \n",
    "            property_label, property_code = designer_intent_get_property(ques)\n",
    "            return property_label, property_code\n",
    "        elif word in ['rating', 'rated', 'rate', 'ratings', 'rates']:\n",
    "            print('rating_intent_get_property')  \n",
    "            property_label, property_code = rating_intent_get_property(ques)\n",
    "            return property_label, property_code\n",
    "        elif word in ['where', 'country', 'location', 'located','place', 'nationality', 'passport', 'citizenship', 'citizen']:\n",
    "            print('location_intent_get_property')  \n",
    "            property_label, property_code = location_intent_get_property(ques)\n",
    "            return property_label, property_code\n",
    "        elif word in ['director', 'directed']:\n",
    "            property_label, property_code = director_intent_get_property(ques) \n",
    "            return property_label, property_code\n",
    "        elif word in ['living', 'occupation']:\n",
    "            print('occupation is the PROPERTY')\n",
    "            property_label = 'occupation'\n",
    "            property_code = 'P106'\n",
    "            return property_label, property_code\n",
    "        elif word in ['executive', 'producer']:\n",
    "            print('executive producer is the property')\n",
    "            property_label = 'executive producer'\n",
    "            property_code = 'P1431'\n",
    "        elif word in ['actor', 'acted', 'acts', 'actress', 'hero', 'heroine']:\n",
    "            print('cast member is the property')\n",
    "            property_label = 'cast member'\n",
    "            property_code = 'P161'\n",
    "            return property_label, property_code\n",
    "         \n",
    "        # elif word in ['Zizou']:\n",
    "        #     intent = 'Tom Meets Zizou'\n",
    "    return property_label, property_code\n",
    "        \n",
    "def check_miscel_intents(ques):\n",
    "    ques = ques.lower()\n",
    "    count = 0\n",
    "    misc_flag = ''\n",
    "    for word in ques.split():\n",
    "        # word = spell.correction(word)\n",
    "        if word in ['comment', 'comments']:\n",
    "            misc_flag = 'comment'\n",
    "            break\n",
    "        elif word in ['plot', 'plots']:\n",
    "            misc_flag = 'plot'\n",
    "            break\n",
    "        elif word in ['imdb', 'top', 'best', 'greatest']:\n",
    "            count = count +1 \n",
    "            if count > 1:\n",
    "                misc_flag = 'imdb' \n",
    "                break\n",
    "\n",
    "    return misc_flag \n",
    "\n",
    "def miscell_comments(entity_name): ## should be a movie\n",
    "    try :\n",
    "        entity_name = entity_name.lower()\n",
    "        answer = comments_df[comments_df['movie label'] == entity_name]['comment'].tolist()\n",
    "        first_comment = answer[0]\n",
    "        comment_to_string = ', '.join([str(x) for x in first_comment])\n",
    "        answer = comment_to_string[:600]\n",
    "    except:\n",
    "        answer = ''\n",
    "    return answer\n",
    "\n",
    "def miscell_plot(entity_code): ## should be a movie\n",
    "    try :\n",
    "        plot = plots_df[plots_df['qid'] == entity_code]['plot'].tolist()\n",
    "        plot_first = plot[0]\n",
    "        plot_to_string = ', '.join([str(x) for x in plot])\n",
    "        answer = plot_to_string[:600]\n",
    "        return answer \n",
    "        \n",
    "    except:\n",
    "        answer = ''\n",
    "    return answer \n",
    "\n",
    "def miscell_imdb(ques):\n",
    "    try:\n",
    "        print(\"inside try\")\n",
    "        number = w2n.word_to_num(ques)\n",
    "        print(number)\n",
    "    except:\n",
    "        if len(re.findall(r'\\d+', ques)) == 0:\n",
    "            number = 5\n",
    "        else :\n",
    "            number = re.findall(r'\\d+', ques)\n",
    "            number = int(number[0])\n",
    "        print(\"inside exception\")\n",
    "    print(\"going to answer\")\n",
    "    print(number)\n",
    "    if number > 10:\n",
    "        number = 10\n",
    "    answer = top_250_imdb_df[:number]['movie label'].tolist()\n",
    "    list_movie = ', '.join(str(item) for item in answer)\n",
    "    answer_label = \"Here are the top \" + str(number) + \" imdb movies of all time: \" + list_movie\n",
    "    return answer_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p, c = get_property_from_intents('what is the rating of Top Gun?')\n",
    "# print(p)\n",
    "# print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REGEXX matching for the movies/human : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_question(ques):\n",
    "    try:\n",
    "\n",
    "        ques = ques.lower()\n",
    "        text_tokens = word_tokenize(ques)\n",
    "        tokens_without_sw = [word for word in text_tokens if not word in stopwords.words()]\n",
    "        print('tokenizer = ' + str(tokens_without_sw))\n",
    "        new_list = [\n",
    "            re.sub(r'[^a-zA-Z0-9 ]+', '', item) for item in tokens_without_sw\n",
    "        ]\n",
    "        new_list = list(filter(None, new_list))\n",
    "        print(new_list)\n",
    "        clean = [\n",
    "            reduce(lambda item,loc: item.replace(loc,''), [item]+greet_and_rem+list_of_crew+list_of_movie_property+list_of_human_prop+list_of_MULTIMEDIA_words+list_of_RECOMMENDATION_words+miscell_list)\n",
    "            for item in new_list\n",
    "        ]\n",
    "        clean = list(filter(None, clean))\n",
    "    except:\n",
    "        clean = []\n",
    "    return clean\n",
    "\n",
    "def fin_entity_matching(ques):\n",
    "    try:\n",
    "        tokens = preprocess_question(ques)\n",
    "        for word in tokens:\n",
    "            test_ans = all_entities_code_description_df.loc[all_entities_code_description_df['description'].str.contains(word, case=False)]\n",
    "            if len(test_ans)>0:\n",
    "                entity_name = test_ans[:1]['description'].item()\n",
    "                entity_code = test_ans[:1]['code'].item()\n",
    "                break\n",
    "    except:\n",
    "        entity_name = ''\n",
    "        entity_code = ''\n",
    "    return entity_name, entity_code\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factual KG + CS + Embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_factual_embed_cs_answers(question):\n",
    "\n",
    "    try:\n",
    "        \n",
    "        entity_name, entity_code, property_name, property_code, result_name, result_code, mov_human_flag = get_factual_answers(question)\n",
    "\n",
    "        if property_name == 'comment':\n",
    "            ans = miscell_comments(entity_name)\n",
    "            # print(ans)\n",
    "            if len(ans) == 0:\n",
    "                ans_message = \"Dang!! We do not have the user comments for the movie \" + entity_name \n",
    "            else:\n",
    "                ans_message = \"Here are the first few characters from one of the comment : \" + entity_name + \" : \" + str(ans)\n",
    "            return ans_message\n",
    "        elif property_name == 'plot':\n",
    "            ans = miscell_plot(entity_code)\n",
    "            # print(ans)\n",
    "            if len(ans) == 0:\n",
    "                # print('ENTITY CODE = ' + entity_code)\n",
    "                ans_message = \"Dang!! We do not have the movie plot for  \" + entity_name \n",
    "            else:\n",
    "                ans_message = \"Here are the first few characters of the plot for the movie \" + entity_name + \" : \" + str(ans)\n",
    "            return ans_message\n",
    "\n",
    "            \n",
    "        property_name_override, property_code_override = get_property_from_intents(question) ## OVERRIDE PROPERTIES\n",
    "        if len(property_name_override) > 0:\n",
    "            property_name = property_name_override\n",
    "            property_code = property_code_override\n",
    "\n",
    "        if len(entity_code) > 0 and len(property_code) > 0 and len(result_code) > 0: # KG + EMB\n",
    "            print(\" 1st CASE :: KG + EMBEDDINGS\")\n",
    "            facual_rank, embedding_rank, embedding_result = get_factual_embedding_rank(property_code, entity_code, result_code, result_name)\n",
    "            if embedding_result == result_name.lower():\n",
    "                answer = embedding_result\n",
    "                ans_message = \"Hey! The \" + property_name + \" of the \" + entity_name + \" is : \" + str(answer.title()) + \". I got this answer verified from the graph as well as the embeddings\"\n",
    "            else:\n",
    "                ans_message = \"Hey!! I have received the \" + property_name + \" of the \" + entity_name + \" as \" + str(result_name.title()) + \" From the KG. But I have received \" + str(embedding_result.title()) + \" as the answer from the embeddings\"\n",
    "            return ans_message\n",
    "        elif len(result_code) == 0 and len(result_name) > 0: # KG + CS\n",
    "            print(\" 2nd CASE :: KG + CS\")\n",
    "            print(\"entity name \" + entity_name)\n",
    "            print(\"property name \" + property_name)\n",
    "            print(\"entity code \" + entity_code)\n",
    "            print(\"property code \" + property_code)\n",
    "            ans_message = \"Hey! I found the answer from the graph!! The \" + property_name + \" of the \" + entity_name + \" is : \" + result_name\n",
    "            result_label_cs, correct_labeled_cs, incorrect_labeled_cs = get_crowd_source_data(entity_code, property_code)\n",
    "            if len(result_label_cs) > 0:\n",
    "                print(\"RECEIVED CROWSOURCED DATA\")\n",
    "                ans_message = str(ans_message) + \" Whereas, the \" + str(property_name) +   \" of \" + str(entity_name) + \" according to the crowd is \" + str(result_label_cs.title()) + \" The crowd had an inter rater agreement of 0.72 in this batch. The result distribution for this task was \" + str(correct_labeled_cs) + \" support votes and \" + str(incorrect_labeled_cs) + \" reject votes.\"\n",
    "            return ans_message\n",
    "        elif len(result_name) == 0 and len(entity_code) > 0 and len(property_code) > 0 : # CS + EMB\n",
    "            print(\" 3rd CASE :: CS + EMBEDDINGS\")\n",
    "            ans_message = ''\n",
    "            result_label_cs, correct_labeled_cs, incorrect_labeled_cs = get_crowd_source_data(entity_code, property_code)\n",
    "            embedding_result2 = get_embedding_result(property_code, entity_code)\n",
    "            if len(embedding_result2) > 0:\n",
    "                ans_message = \"According to the embeddings, \" + property_name + \" of \" + entity_name + \" is \" + str(embedding_result2.title())\n",
    "\n",
    "            if len(result_label_cs) > 0:\n",
    "                print(\"RECEIVED CROWSOURCED DATA\")\n",
    "                ans_message = str(ans_message) + \" Whereas, I also have the result from the crowd as : \" + str(result_label_cs.title()) + \" The crowd had an inter rater agreement of 0.72 in this batch. The result distribution for this task was \" + str(correct_labeled_cs) + \" support votes and \" + str(incorrect_labeled_cs) + \" reject votes.\"\n",
    "\n",
    "            if len(embedding_result2) == 0 and len(result_label_cs) == 0:\n",
    "                ans_message = \"Hey Hooman!! You got me this time. I did not find the answer to this question. I checked the KG, the embeddings and the crowdsourced data. Please give me another chance with a different question \"\n",
    "            return ans_message\n",
    "\n",
    "        elif len(entity_code) > 0 and len(property_code) == 0 : \n",
    "            print(\" 4th CASE :: Description\")\n",
    "            print(\"NO PROPERTY DETECTED. ONLY THE ENTITY NAME IS DETECTED. RETURNING THE DESCRIPTION and IMAGE\")\n",
    "            if mov_human_flag == 'movie':\n",
    "                table_to_query = movie_info\n",
    "                target_property = 'description'\n",
    "                description , _ = result_generator_movie(target_property, table_to_query , entity_name)\n",
    "                ans_message = \"I am very sorry that i did not understand the property of \" + entity_name + \" , which is a \" + description \n",
    "            elif mov_human_flag == 'human':\n",
    "                table_to_query = human_info\n",
    "                target_property = 'description'\n",
    "                description , _ = result_generator_human(target_property, table_to_query, entity_name)\n",
    "                ans_message = \"I am very sorry that i did not understand the property of \" + entity_name + \" , who is a \" + description\n",
    "            return ans_message\n",
    "            \n",
    "        elif len(entity_code) == 0 and len(property_code) > 0:                # HERE WE ONLY HAVE THE PROPERTY\n",
    "            print(\" 5th CASE :: Random answer for the property\")\n",
    "            embedding_result3 = get_embedding_result(property_code, 'Q110138')\n",
    "            if len(embedding_result3) == 0:\n",
    "                embedding_result4 = get_embedding_result(property_code, 'Q37079')\n",
    "                if len(embedding_result4) == 0:\n",
    "                    ans_message = \"soo.. I believe the \" + property_name + \" is : William\"\n",
    "                else:\n",
    "                    ans_message = \"voila!! The \" + property_name + \" is : \" + str(embedding_result4)\n",
    "            else:\n",
    "                ans_message = \"voila!! The \" + property_name + \" is : \" + str(embedding_result3)\n",
    "            return ans_message\n",
    "\n",
    "        else:\n",
    "            ans_message = \"Daammnnn!! That was a tough one!! Can you please try to capitalise the first letter of the movie names and the entity name or try with an easier property, please ;)\"\n",
    "            return ans_message\n",
    "\n",
    "    except:\n",
    "        ans_message = \"Wooff!! I did not see that coming!! Can you please try to titalise the entity name or try with an easier property, please ;)\"\n",
    "    return ans_message       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENDGAME "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question = 'show me the image of johhnny depp'\n",
    "# question = 'What does Rohit Shetty look like?'\n",
    "# question = 'Recommend movies like Nightmare on Elm Street, Friday the 13th, and Halloween.'\n",
    "# question = 'show me some comments from teh movie Cliffhanger'\n",
    "question = 'What is the place of burial of Sushant Singh Rajput'\n",
    "question = 'What is the place of death of Sushant Singh Rajput'\n",
    "question = 'What is the place of death of Shahrukh Khan'\n",
    "question = 'Who is Shah Rukh Khan'\n",
    "question = 'show me a still of Shah Rukh Khan'\n",
    "question = 'who is the costume designer of Shape of Water'\n",
    "# question = 'who is the art director of Shape of Water'\n",
    "# question = 'who is the prodcution designer of Shape of Water'\n",
    "# question = 'what is the narrative location of Dangal'\n",
    "# question = 'who is teh actor in Dangal'\n",
    "# question = 'Recommend movies like Nightmare on Elm Street, Friday the 13th, and Halloween.'\n",
    "# question = 'Who is the executive producer of X-Men: First Class?'\n",
    "# question = 'Can you tell me the publication date of Tom Meets Zizou?'\n",
    "# question = 'What is the box office of The Princess and the Frog?'\n",
    "# question = 'Given that I like The Lion King, Po cahontas, and The Beauty and the Beast, can you recommend some movies?'\n",
    "# question = 'Recommend movies similar to Hamlet and  Othello.'\n",
    "# question = 'Recommend movies like Nightmare on Elm Street, Friday the 13th, and Halloween.'\n",
    "# question = 'Who is the executive \n",
    "# producer of Naruto the Movie: Guardians of the Crescent Moon Kingdom?'\n",
    "# question = 'who is the screenwriter of Free Willy 3: The Rescue?' #**\n",
    "# question = 'occupation of Jean Van Hamme' \n",
    "question = 'What is the MPAA film rating of Weathering with You?'\n",
    "# question = 'who is the executive producer of TOP Gun' # **\n",
    "# question = 'who is the director  of TOP Gun' # **\n",
    "# question = 'Who is the executive producer of Naruto the Movie: Guardians of the Crescent Moon Kingdom?'\n",
    "# question = 'Who is the screenwriter of Free Willy 3: The Rescue ?'\n",
    "# question = 'Who is the executive producer of Naruto the Movie?'\n",
    "# question = 'Who is the screenwriter of The Masked Gang: Cyprus?'\n",
    "# question = 'What is the genre of Good Neighbors?'\n",
    "# question = 'Who is the director of Star Wars: Episode VI - Return of the Jedi?'\n",
    "# question = 'Who directed The Bridge on the River Kwai?'\n",
    "# question = 'Who is the director of Good Will Hunting?'\n",
    "# question = 'who is the screenwriter of Free Willy 3: The Rescue?'\n",
    "# question = 'occupation of Jean Van Hamme'\n",
    "# question = 'who is the executive producer of TOP Gun '\n",
    "# question = 'Who is the executive producer of Naruto the Movie: Guardians of the Crescent Moon Kingdom?'\n",
    "# question = 'Who is the screenwriter of Free Willy 3: The Rescue ?'\n",
    "# question = 'Show me a picture of Halle Berry.'\n",
    "# ques = 'hey! can you tell me the director of the movie Naruto the Movie: Guardians of the Crescent Moon Kingdom'\n",
    "# ques = 'What is the MPAA film rating of Weathering with You?'\n",
    "# # ques = 'Recommend movies similar to Hamlet and Othello.'\n",
    "# ques = 'What is the MPAA film rating of Weathering with You?'\n",
    "\n",
    "def get_answers_prod(question):\n",
    "    try:\n",
    "        if len(question) < 15:\n",
    "            candidate_labels = ['positive sentiment', 'negative sentiment', 'greeting', 'neutral']\n",
    "            question_intent = zero_shot_classifier(question, candidate_labels)\n",
    "            user_intent = question_intent['labels'][0]\n",
    "            if user_intent == 'positive sentiment':\n",
    "                answer = \"I am glad that you liked the answer. Try out some more questions :D\"\n",
    "            elif user_intent == 'negative sentiment':\n",
    "                answer = \"I am soo sorry you did not like my answer. I will try my best in the next one :D\"\n",
    "            elif user_intent == 'greeting':\n",
    "                answer = \"Hello dear human!! I hope you are well. Let's start the QnA round to test me out :D\"\n",
    "            elif user_intent == 'neutral':\n",
    "                answer = \"Try some more questions.. :)\"\n",
    "            return answer\n",
    "\n",
    "        flag = check_miscel_intents(question)\n",
    "        if flag == 'imdb':\n",
    "            answer = miscell_imdb(question)\n",
    "            return answer\n",
    "        intent, intent_word_image = check_image_recommendation (question)\n",
    "        if intent == 'image':\n",
    "            print(\"IMAGE QUESTION\")\n",
    "            answer = get_image(question)\n",
    "        elif intent == 'recommendation':\n",
    "            print(\"RECOMMENDATION QUESTION\")\n",
    "            answer =  get_recommendations_n_entity(question)\n",
    "        else :\n",
    "            print(\"KG EMBEDDING CS QUESTION\")\n",
    "            answer = get_factual_embed_cs_answers(question)\n",
    "            return answer\n",
    "        \n",
    "    except:\n",
    "        answer = \"Oops! I got some unprecedented error. Please ask me another question. Thanks :)\"\n",
    "    return answer\n",
    "\n",
    "print(get_answers_prod(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONNECTION TO THE API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import atexit\n",
    "import getpass\n",
    "import requests  # install the package via \"pip install requests\"\n",
    "from collections import defaultdict\n",
    "\n",
    "# url of the speakeasy server\n",
    "url = 'https://speakeasy.ifi.uzh.ch'\n",
    "listen_freq = 3\n",
    "\n",
    "\n",
    "class DemoBot:\n",
    "    def __init__(self, username, password):\n",
    "        self.agent_details = self.login(username, password)\n",
    "        self.session_token = self.agent_details['sessionToken']\n",
    "        self.chat_state = defaultdict(lambda: {'messages': defaultdict(dict), 'initiated': False, 'my_alias': None})\n",
    "\n",
    "        atexit.register(self.logout)\n",
    "\n",
    "    def listen(self):\n",
    "        while True:\n",
    "            # check for all chatrooms\n",
    "            current_rooms = self.check_rooms(session_token=self.session_token)['rooms']\n",
    "            for room in current_rooms:\n",
    "                # ignore finished conversations\n",
    "                if room['remainingTime'] > 0:\n",
    "                    room_id = room['uid']\n",
    "                    if not self.chat_state[room_id]['initiated']:\n",
    "                        # send a welcome message and get the alias of the agent in the chatroom\n",
    "                        self.post_message(room_id=room_id, session_token=self.session_token, message=f'Hello dear human, I am your movie wikipedia. You can ask me 1) factual questions related to the directors, screenwriters, ratings, date of publication of the movies. 2) I can answer questions related to the place of birth, place of death, occupation of the humans. 3) images from the movies and portraits of film actor/actress. 4) I can recommend you movies similar to what you like. 5) Plots and user comments for the movies. 6) list of top imdb movies. 7) Replies to your greetings and remarks. PS - Please note that the proper nouns (For ex. name of the person or a movie should start with a capital letter :) Thanks for your understanding. Also, you can write \"good, nice, etc\" to prasie the answer if you like and can criticise it as well. lets get started :)')\n",
    "                        self.chat_state[room_id]['initiated'] = True\n",
    "                        self.chat_state[room_id]['my_alias'] = room['alias'] # ******* CHECK THIS LATER *******\n",
    "\n",
    "                    # check for all messages\n",
    "                    all_messages = self.check_room_state(room_id=room_id, since=0, session_token=self.session_token)['messages']\n",
    "\n",
    "                    # you can also use [\"reactions\"] to get the reactions of the messages: STAR, THUMBS_UP, THUMBS_DOWN\n",
    "\n",
    "                    for message in all_messages:\n",
    "                        if message['authorAlias'] != self.chat_state[room_id]['my_alias']:\n",
    "\n",
    "                            # check if the message is new\n",
    "                            if message['ordinal'] not in self.chat_state[room_id]['messages']:\n",
    "                                self.chat_state[room_id]['messages'][message['ordinal']] = message\n",
    "                                print('\\t- Chatroom {} - new message #{}: \\'{}\\' - {}'.format(room_id, message['ordinal'], message['message'], self.get_time()))\n",
    "\n",
    "                                ##### You should call your agent here and get the response message #####\n",
    "                                # response = full_function(message['message'], room_id).encode('utf-8') # resp\n",
    "                                # response = 'Here is the image image:3543/rm1853225728'\n",
    "                                response = get_answers_prod(message['message'])\n",
    "                                self.post_message(room_id=room_id, session_token=self.session_token, message = response)\n",
    "                                # self.post_message(room_id=room_id, session_token=self.session_token, message='Got your message: \\'{}\\' at {}.'.format(message['message'], self.get_time()))\n",
    "            time.sleep(1) ##\n",
    "\n",
    "    def login(self, username: str, password: str):\n",
    "        agent_details = requests.post(url=url + \"/api/login\", json={\"username\": username, \"password\": password}).json()\n",
    "        print('- User {} successfully logged in with session \\'{}\\'!'.format(agent_details['userDetails']['username'], agent_details['sessionToken']))\n",
    "        return agent_details\n",
    "\n",
    "    def check_rooms(self, session_token: str):\n",
    "        return requests.get(url=url + \"/api/rooms\", params={\"session\": session_token}).json()\n",
    "\n",
    "    def check_room_state(self, room_id: str, since: int, session_token: str):\n",
    "        return requests.get(url=url + \"/api/room/{}/{}\".format(room_id, since), params={\"roomId\": room_id, \"since\": since, \"session\": session_token}).json()\n",
    "\n",
    "    def post_message(self, room_id: str, session_token: str, message: str):\n",
    "        tmp_des = requests.post(url=url + \"/api/room/{}\".format(room_id),\n",
    "                                params={\"roomId\": room_id, \"session\": session_token}, data=message).json()\n",
    "        if tmp_des['description'] != 'Message received':\n",
    "            print('\\t\\t Error: failed to post message: {}'.format(message))\n",
    "\n",
    "    def get_time(self):\n",
    "        return time.strftime(\"%H:%M:%S, %d-%m-%Y\", time.localtime())\n",
    "\n",
    "    def logout(self):\n",
    "        if requests.get(url=url + \"/api/logout\", params={\"session\": self.session_token}).json()['description'] == 'Logged out':\n",
    "            print('- Session \\'{}\\' successfully logged out!'.format(self.session_token))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    username = 'kartikey.sharma_bot'\n",
    "    password = getpass.getpass('Password of the demo bot:')\n",
    "    demobot = DemoBot(username, password)\n",
    "    demobot.listen()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit ('atai_proj')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b5389c4624116717422a214fec8afe109855e6e3538d73a25be708f3271d7807"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
